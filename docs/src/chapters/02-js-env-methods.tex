\chapter{Język JavaScript}

JavaScript od momentu swojego powstania w~1995 roku stanowi jeden z~filarów rozwoju technologii webowych, zaczynając od dodania prostych mechanizmów interaktywności do statycznych stron internetowym, a~kończąc na byciu nieraz jedynym samodzielnym budulcem pełnowymiarowych aplikacji działających po stronie klienta i~serwera, aplikacji działających w~środowisku przeglądarki internetowej, ale też w~środowiskach natywnych, desktopowych i~mobilnych. Dlatego, aby zrozumieć w~pełni specyfikę problemu, który stanowi przystosowanie języka do wykonywania obliczeń numerycznych, w~tym rozdziale przybliżone zostały zagadnienia związane z~modelem wykonania, środowiskami oraz sposobami na podział kodu na moduły i~późniejsze ich wykorzystanie. Na końcu opisane zostały metody akceleracji, dla których przeprowadzono badania.



\section{Model wykonania}

Model wykonania języka JavaScript skoncentrowany jest w~głównej mierze na obsłudze zdarzeń. W~przeglądarce internetowej zdarzeniami takimi mogą być interakcje z~użytkownikiem, na przykład kiedy naciśnięty zostanie przycisk, albo interakcje z~siecią, kiedy otrzymamy odpowiedź na zapytanie z~wykorzystaniem obiektu \lstinline{XMLHttpRequest} lub skorzystamy z~Fetch API. Po stronie serwera zdarzeniami takimi mogą być odebranie zapytania, które serwer musi obsłużyć, obsługa strumieni, ale także wszelkie odpowiedzi na interakcje z~systemem operacyjnym. Podstawowymi interakcjami mogą być obsługa sygnałów, dostęp do plików, czy też obsługa sieci, która umożliwia połączenie na przykład z~bazą danych.

Zdarzenia te obsługuje pętla zdarzeń (ang. event loop). Na rysunku \ref{fig:event-loop} pokazano jej uproszczony model. Wyróżnia ona zadania, zwane także makro zadaniami, oraz mikro zadania. Dla każdego typu zadań utworzona zostaje osobna kolejka. Jeśli aktualnie wykonywane przetwarzanie sekwencyjne, którego ramki wywołań śledzone są na stosie, zakończy się, wtedy z~pętli zdarzeń pobierane i~wykonywane jest makro lub mikro zadanie. W~pierwszej kolejności wykonywane są wszystkie mikro zadania, a~gdy ich kolejka jest pusta, wykonywane jest kolejne makro zadanie.

Makro zadania dodawane są do kolejki, aby obsłużyć wspomniane już zdarzenia związane z~działaniami użytkownika lub inne zewnętrzne zdarzenia. Są one również dodawane do kolejki, kiedy mija czas zadany podczas wywołań funkcji \lstinline{setTimeout()} oraz \lstinline{setInterval()}. Warto zaznaczyć, że wywołania tych funkcji nie gwarantują wykonania dokładnie po zadanym czasie, ale traktują go jako próg czasowy, po jakim zadana funkcja zostanie dodana do kolejki makro zadań \cite{setTimeout}. Makro zadania dodane podczas jednej iteracji pętli nigdy nie zostaną wykonane w~tej samej iteracji.

Mikro zadania pochodzą tylko i~wyłącznie z~kodu użytkownika, bądź bibliotek i~wykorzystywane są do obsługi asynchronicznych zadań, zarządzania ich kolejnością i~obsługą błędów\cite{runtime}. Do ich tworzenia wykorzystuje się głównie obiekt \lstinline{Promise}}, który reprezentuje zadanie, które w~przyszłości zakończy się pomyślnie lub błędem. Dla takiego obiektu zdefiniować możemy funkcje, które wykonają się podczas scenariusza pomyślnego (\lstinline{then}), błędnego (\lstinline{catch}) oraz zawsze (\lstinline{finally}) \cite{promise}. Mikro zadania pochodzić mogą również od obserwatorów na przykład \lstinline{MutationObserver}, czy \lstinline{ResizeObserver}.

Zrozumienie sposobu wykonywania kodu w~asynchronicznym modelu języka JavaScript jest kluczowe do efektywnego wykorzystania możliwości, jakie idą za metodami akceleracji, których użycie możliwe jest tylko i~wyłącznie poprzez asynchroniczne wywołania. Opisane w~sekcji \ref{sec:acc-methods} metody bazujące na Worker'ach oraz WebGL wymagają interakcji poprzez wywołania asynchroniczne. Na listingu \ref{lst:async} pokazano przykład kodu asynchronicznego. Wywołania \mbox{\lstinline{console.log}} wykonają się, zawsze drukując liczby w~kolejności od 1 do 6.

\lstinputlisting[language=JavaScript, caption=Przykład kodu demonstrujący mechanizmy asynchroniczności w~języku JavaScript., label=lst:async] {./code/async.js}

Linijki 1 oraz 6 zostają wykonane synchronicznie. \lstinline{Promise} w~linijce 5 zostaje wykonany jako następny, ponieważ jako mikro zadanie, wykona się zaraz po operacjach synchronicznych. Następnie funkcje \lstinline{setTimeout} wykonają się w~kolejności ich wywołania, gdzie w~linijkach 2-4 na ich kolejność wpływ maja mechanizm \lstinline{Promise}. Timeout z~linijki 3, a~potem 4 zostają wywołane jaki pierwsze. Jako ostatni wykonuje się timeout z~linijki 2, ponieważ jego wywołanie, w~postaci mikro taska, przeniesione zostało na koniec wykonania synchronicznego.

\begin{figure}
    \centering
    \input{drawings/eventLoop}
    \caption{Uproszczony model pętli zdarzeń środowisk języka JavaScript w~wariancie z~wyróżnieniem API przeglądarek internetowych.}
    \label{fig:event-loop}
\end{figure}

\section{Środowiska JavaScript}
\label{sec:env-modules}

Rosnąca popularność języka JavaScript i~idących za jego stosowaniem możliwości przyspieszyła rozwój środowisk, w~których kod języka mógł być wykonywany. Pierwszym z~nich była przeglądarka internetowa. 

\subsection{Przeglądarka internetowa}

Głównym zadaniem przeglądarki internetowej jest pobieranie z~sieci i~wyświetlanie zawartości użytkownikowi oraz obsługa jego interakcji. Najważniejszym komponentem przeglądarki jest silnik renderujący, który zawiera między innymi silniki odpowiedzialne za parsowanie i~renderowanie struktury modelu DOM, adaptery służące do wywołań dostępnych bibliotek graficznych (OpenGL, Vulcan, DirectX) oraz silnik JavaScript. Z~perspektywy problemu stawianego w~tej pracy to właśnie silnik JavaScript jest najważniejszym komponentem silnika renderującego. Silnik języka zajmuje się parsowaniem, kompilacją do bytecode'u, interpretowaniem oraz późniejszą optymalizacją kodu. Posiada wiele możliwości optymalizacji spekulatywnej z~racji na specyfikę języka, który jest dynamicznie typowany \cite{meurer_2017}.

Popularnymi silnikami renderującymi są Blink z~silnikiem JavaScript V8 \cite{V8} oraz Gecko z~silnikiem JavaScript SpiderMonkey \cite{spidermonkey}. Silniki JavaScript skupione są na szybkim i~efektywnym wykonywaniu kodu i~nie zajmują się asynchronicznością i~pętlą zdarzeń. Odpowiedzialne za to są równolegle biblioteki. W~przeglądarce Google Chrome pętlę zdarzeń implementuje biblioteka LibEvent \cite{libevent}.

\subsection{NodeJS}

NodeJS jest powstałym w~2009 roku środowiskiem, które było odpowiedzią na architekturę pozostałych rozwiązań serwerowych, które angażują wiele procesów i~wątków do obsługi wielu zapytań w~tym samym czasie. Rodzi to problemy związane z~koniecznością przełączania kontekstu pomiędzy procesami oraz większe zapotrzebowanie na pamięć. Również każda operacja wejścia-wyjścia musi być synchroniczna, co prowadzi do zablokowania całego procesu w~oczekiwaniu na odpowiedź \cite{nodejs}.

Problemy te rozwiązało środowisko NodeJS, napisane w~C++ i~oparte na silniku V8. Razem biblioteką LibUv \cite{libuv} implementującą pętlę zdarzeń w~ramach jednego procesu wykonującego kod JavaScript użytkownika oraz wielu wątków, które realizują oczekiwanie na operacje asynchroniczne, pozwoliło rozwiązać problem operacji wejścia-wyjścia pozwalając w~ramach tych samych zasobów sprzętowych osiągnąć lepsza wydajność niż popularny serwer Apache \cite{node-apache}. Na rysunku \ref{fig:nodejs} pokazano architekturę środowiska NodeJS, która stoi pomiędzy aplikacją, a~systemem operacyjnym.

\begin{figure}
    \centering
    \input{drawings/node} 
    \caption{Model architektury środowiska NodeJS.}
    \label{fig:nodejs}
\end{figure}

\subsection{Deno}

Deno powstał w~2018 roku, a~jego wersja 1.0.0 wydana została w~2020 roku. Jest to środowisko aspirujące do bycia następcą NodeJS rozwiązując jego problemy związane z~bezpieczeństwem, systemem budowania zależności bibliotek, czy importowania zależności \cite{deno}. Podobnie jak NodeJS do wykonywania kodu JavaScript wykorzystuje silnik V8, ale napisany jest w~języku Rust. Do obsługi asynchroniczności i~pętli zdarzeń wykorzystuje bibliotekę Tokio \cite{tokio}. W~przeciwieństwie do NodeJS i~przeglądarek internetowych obsługuje natywnie TypeScript - nadzbiór języka JavaScript umożliwiający wykorzystanie statycznego typowania oraz wszystkie zalety za tym idące.

\section{Modularność i~kompatybilność kodu}

Kolejnym ważnym aspektem rozważań jest modularność i~kompatybilność kodu pomiędzy środowiskami. Rozwój bibliotek języków jest naturalnym krokiem ewolucji ich ekosystemów i~aby taki ekosystem był ogólnodostępny, biblioteki dostępne są dla wszystkich w~postaci scentralizowanego rejestru paczek. 

\subsection{Modularność}

Dla środowiska NodeJS najpopularniejszym rejestrem jest \textit{npm registry} (node package manager). Za pomocą narzędzia o~tej samej nazwie można instalować i~zatrzaskiwać wersję paczek, które trafiają do folderu \lstinline{node_modules}, w~którym środowisko NodeJS domyślnie poszukuje kodu podczas importu paczek. Zainstalowane paczki są opisane wraz z~ich wersją w~pliku \mbox{\lstinline{package.json}} i~\lstinline{package-lock.json}, gdzie pierwszy z~nich zawiera wymaganą wersję zapisaną w~konwencji Semver \cite{semver}, a~drugi zatrzaśnięte zainstalowane wersje, co pozwala odtworzyć dokładną strukturę zależności.

Przeglądarki internetowe z~kolei pobierają dodatkowe biblioteki poprzez umieszczenie tagów \lstinline{<script/>} w~dowolnym miejscu na stronie, często z~użyciem sieci CDN (ang. content delivery network). \textit{npm} jest również popularnym rozwiązaniem służącym do dostarczania modułów niezbędnych do funkcjonowania stronom internetowym, jednak odbywa się to pośrednio. Za pomocą narzędzi zwanych bundler'ami, ze wszystkich niezbędnych zależności - właściwego kodu strony oraz zewnętrznych bibliotek instalowanych przy pomocy narzędzia \textit{npm}, budowany jest pojedynczy plik, który następnie jest ładowany przez przeglądarkę. Pomaga to zaoszczędzić liczbę połączeń przeglądarki do serwerów, a~co za tym idzie zaoszczędzić czas spędzony na inicjowaniu połączenia i~pobieraniu danych w~szczególności, że liczba możliwych otwartych połączeń przez przeglądarkę internetową jest limitowana (10 w~Google Chrome). Często obecnie budowane są dwa lub więcej plików - jeden z~bibliotekami zewnętrznymi oraz jeden lub więcej z~właściwym kodem strony w~celu wykorzystania mechanizmów pamięci podręcznej przeglądarki oraz dynamicznego i~opóźnionego ładowania niezbędnego kodu, co przyspiesza ładowanie strony. Popularnymi bundler'ami są Webpack, Snowpack, Parcel, Rollup oraz Vite.

Deno próbuje rozwiązać problem importowania modułów w~NodeJS, który wynika z~scentralizowanego rejestru i~paczek oraz z~faktu istnienia plików \lstinline{package*.json} i~konieczności wykonania procesu instalacji. Pobiera on zależności bezpośrednio z~sieci i~umieszcza w~pamięci podręcznej. Link do zależności jest jej jednoznacznym identyfikatorem, a~to znaczy, że powinien zawierać wersję paczki i~nigdy nie zmienić swojej zawartości. Pobranie i~kompilacja zależności w~czasie wykonania programu likwiduje potrzebę przechowywania listy zależności i~ich wersji oraz niweluje potrzebę ich instalacji. Deno wykorzystuje opisany w~dalszej części rozdziału format modułów ESM.

Niezależnie od tego gdzie przetrzymywane są moduły oraz w~jaki sposób są zarządzane przez środowisko, muszą one być finalnie przez nie skonsumowane. Mogą być one użyte bezpośrednio, ale też przetransformowane w~procesie budowania biblioteki, która będzie potem dalej konsumowana, czy paczki dla przeglądarki internetowej. W~procesie ewolucji ekosystemu języka JavaScript wykształciło się wiele formatów modułów. Niektóre z~nich są kompatybilne tylko z~przeglądarką internetową, niektóre tylko ze środowiskiem NodeJS bądź Deno.  

\subsubsection{AMD}

AMD (Asynchronous Module Definition) jest sposobem ładowania zależności w~przeglądarkach internetowych. Rozwija wzorzec modułów JavaScript \cite{jsmodulepattern} poprzez dodanie asynchronicznego pobierania i~ładowania zależności. Moduł jest funkcją, dzięki czemu zadeklarowane zmienne nie wyciekają poza jej zakres, a~jej wartość zwracana stanowi wartość, którą taki moduł eksportuje. Zadeklarowanie modułu i~jego zależności w~formacie AMD umożliwia funkcja \lstinline{define}.

\subsubsection{CommonJS}

Format CommonJS utworzony został na potrzeby środowiska NodeJS i~jest tam do dzisiaj wykorzystywany. Używa on globalnie dostępnej funkcji \lstinline{require}, która jako argument przyjmuje nazwę modułu lub relatywną ścieżkę do pliku \lstinline{*.js}, jednak z~pominięciem jego rozszerzenia, co stanowi problem podczas wyszukiwania modułów przez środowisko. Moduł może eksportować funkcje i~wartości poprzez dodanie ich do obiektu \lstinline{module.exports}. Pliki z~modułami w~tym formacie, aby lepiej je identyfikować, mogą mieć rozszerzenie \lstinline{*.cjs}.

\subsubsection{UMD}

UMD (Universal Module Definition) nie stanowi samodzielnego formatu, ale integruje formaty AMD, CommonJS oraz użycie zmiennych globalnych do definicji modułu i~jego zależności. Wyewoluował on z~potrzeby tworzenia bibliotek kompatybilnych z~wieloma środowiskami, dla których nie trzeba budować wielu wersji w~różnych formatach.

\subsubsection{Moduły ECMAScript}

Brak kompatybilności i~wiele formatów modułów, gdzie każde środowisko zaproponowało swój własny, wymusiło ich standaryzację w~specyfikacji języka. ECMAScript, którego implementacją jest JavaScript, w~wersji 2015 (zwanej również ES6) wprowadza definicję modułów zwanych ESModules, ESM \cite{ESModules}. Obecnie wspierane są one przez wszystkie analizowane tutaj środowiska i~są zalecaną metodą importowania zależności. Używają one słów kluczowych \lstinline{import} oraz \lstinline{export} tak, jak zostało to pokazane na listingu \ref{lst:esm}. Od wersji ES11 specyfikacji możliwe stało się dynamiczne importowanie modułów podczas wykonania, gdzie jako rezultat otrzymujemy obiekt \mbox{\lstinline{Promise}}. Pliki z~modułami w~tym formacie, aby lepiej je identyfikować, mogą mieć rozszerzenie \mbox{\lstinline{*.mjs}}. Wszystkie biblioteki wykorzystujące metody akceleracji badane w~tej pracy budowane są z~wykorzystaniem ESM.

\begin{lstlisting}[language=JavaScript, caption=Przykład wykorzystania ECMAScript Modules, label=lst:esm]
// main.mjs
import { add } from "./module"
console.log(add(2+2));

// module.mjs
export function add(foo, bar) { return foo + bar; }
\end{lstlisting}

\subsection{Kompatybilność}

Szerokie starania w~standaryzacji modułów umożliwiają tworzenie kodu kompatybilnego z~wieloma środowiskami. Jeśli jednak kod ten korzysta z~funkcjonalności samego środowiska, która istnieje w~pozostałych środowiskach, ale ich API nie są ze sobą zgodne, problem kompatybilności między środowiskami wciąż występuje. Wprowadza to niechciane mechanizmy do kodu wykrywające środowisko i~wymusza wykorzystanie wzorców projektowych takich jak \textit{adapter}, w~celu obsługi wszystkich wariantów API.

Przykładem takiego rozwiązania jest biblioteka \textit{axios}, która służy do wykonywania zapytań HTTP. W~środowisku przeglądarki internetowej do wykonywania zapytań wykorzystuje obiekt \lstinline{XMLHttpRequest}, a~w środowisku NodeJS wbudowany moduł \textit{http}. Rozwiązaniem problemu w~tym przypadku może być użycie Fetch API, które jako pierwsze zadebiutowało w~przeglądarkach internetowych oraz zaadaptowane zostało przez NodeJS, a~w Deno jest ono domyślnie przewidzianą formą wykonywania zapytań HTTP.

Innym przykładem braku kompatybilności pomiędzy podobnymi funkcjonalnościami jest wielowątkowość, która istnieje pod abstrakcją Worker'ów i~dokładnie zostanie omówiona w~rozdziale \ref{sec:acc-methods}. Przeglądarki internetowe oraz Deno, który ma na celu możliwie zbliżyć się do nich ze swoim API, implementują Web Worker API. NodeJS z~kolei do obsługi Worker'ów wykorzystuje wbudowany moduł \textit{worker\_threads}, który różni się od jego odpowiedników w~pozostałych środowiskach.    

\section{Metody akceleracji}
\label{sec:acc-methods}

Akceleracja obliczeń jest niekończącą się pogonią za nieskończenie krótkim czasem wykonania algorytmów. Zdaniem autora powinna być ona brana pod uwagę na każdym etapie ich rozwoju - od etapu prototypowania, do wdrożeń produkcyjnych, ponieważ na każdym z~nich może przynieść wymierne korzyści. Wspomnianą w~poprzednim rozdziale akcelerację praca traktuje jako wszelkie metody przyspieszające wykonywanie algorytmu.

\subsection{Optymalizacja wykonania sekwencyjnego}

Pierwszym aspektem, na który trzeba zwrócić uwagę jest sama interakcja z~silnikiem języka i~wykorzystanie jego możliwości oraz tego, w~jaki sposób potrafi on optymalizować wykonywany kod. Poprzez kompilację kodu Just-In-Time (JIT), czyli bezpośrednio przed jego wykonaniem oraz możliwość powtarzania tego procesu wykorzystując heurystyki dla zebranych danych, możliwe jest przyspieszenie wykonania kodu \cite{meurer_2017}. W~przypadku silnika V8 kod najpierw trafia do interpretera o~nazwie Ignition, gdzie kompilowany jest do bytecode'u, który zamieniany jest na instrukcje zgodne z~architekturą procesora. Równolegle bytecode wysyłany jest do kompilatora TurboFan, gdzie przechodzi optymalizację na poziomie funkcji, w~przeciwieństwie do innych rozwiązań JIT, które identyfikują wielokrotnie wykonywaną część bytecode'u \cite{meurer_2019}. Optymalizacja ta jest ograniczona do funkcji o~maksymalnym rozmiarze bytecode'u równym 60KB, więc ważne jest, aby umiejętnie rozbijać kod algorytmu na funkcje i~moduły.

Osoba projektująca dany algorytm może celowo unikać konstrukcji języka oraz niektórych wzorców, aby wspomóc mechanizmy optymalizacji i~zwiększyć wydajność w~skrajnych przypadkach nawet o~25\% (\cite{gong2015jitprof}, \cite{selakovic2016performance}). Dobrą praktyką jest stosowanie typowanych tablic (Typed Array) do przechowywania danych binarnych oraz danych o~znanym typie. Innym sposobem poprawny wydajności jest modyfikacja algorytmu tak, aby zredukować obciążenie związane z~obliczeniami zmiennoprzecinkowymi, na przykład poprzez stosowanie stablicowanych wartości funkcji trygonometrycznych (LUT).

\subsection{Natywne moduły}

Środowiska NodeJS i~Deno działające po stronie serwera pozwalają na uruchomienie z~ich poziomu bibliotek skompilowanych do kodu maszynowego konkretnej architektury. Deno pozwala uruchomić funkcję ze skompilowanego kodu języka Rust do postaci biblioteki na różnych platformach (\lstinline{*.so}, \lstinline{*.dll}, \lstinline{*.dylib}). NodeJS natomiast posiada własny system budowania natywnych modułów z~kodu C++ o~nazwie \textit{node-gyp}, którego zależnością jest język Python.

Zaletą korzystania z~natywnych modułów jest możliwość wykorzystania metod optymalizacji specyficznych dla platformy sprzętowej, jakie oferują języki niskiego poziomu kompilowane do kodu maszynowego. Metodę tę można rozwinąć o~metody akceleracji dostępne w~językach źródłowych, których przykładem może być wielowątkowość z~wykorzystaniem biblioteki \lstinline{pthreads}. Do wad takiego rozwiązania zaliczyć można konieczność pobierania lub budowania natywnych zależności w~momencie instalacji biblioteki oraz ogólną kompatybilność, która wykracza poza środowisko języka JavaScript. Wadą, która wpływa w~znaczącym stopniu na wydajność w~specyficznych przypadkach jest brak bezpośredniego dostępu do pamięci silnika JavaScript, co skutkuje koniecznością kopiowania danych w~warstwie powiązania natywnego modułu z~kodem języka JavaScript. Dla dużych danych proces ten okazać się może wąskim gardłem algorytmu.

\subsection{WebAssembly}

Kolejną metodą akceleracji wykonania sekwencyjnego jest WebAssembly (WASM), który jest językiem niskiego poziomu. Stanowi on cel kompilacji języków takich jak C++, czy Rust i~pozwala uruchamiać w~środowisku webowym złożone aplikacje, których wcześniejsze uruchomienie nie było możliwe ze względu na konieczność parsowania i~kompilacji dużej ilości kodu. Umożliwiło to na przykład łatwe przeniesienie aplikacji napisanych w~języku C++ z~wykorzystaniem biblioteki Qt i~uruchomienie ich w~przeglądarce internetowej \cite{qt-wasm}. Kolejnym przykładem jest jeden z~backend'ów biblioteki Tensorflow.js \cite{tensorflowjs}, która umożliwia trenowanie i~wdrażanie modeli uczenia maszynowego. Dzięki bibliotece PyScript, która portuje implementację języka Python napisaną w~C do języka WebAssembly, możliwe stało się wykonywanie kodu języka w~przeglądarce internetowej \cite{pyscript}.

\begin{lstlisting}[language=C++, caption=Funkcja licząca silnię w~języku C/C++, label=lst:factorial-cpp]
int factorial(int n) {
    if (n == 0)
        return 1;
    else
        return n * factorial(n-1);
}
\end{lstlisting}
    
\begin{lstlisting}[language=WASM, caption=Funkcja licząca silnię w~języku WASM, label=lst:factorial-wasm]
(func (param i64) (result i64)
    local.get 0
    i64.eqz
    if (result i64)
        i64.const 1
    else
        local.get 0
        local.get 0
        i64.const 1
        i64.sub
        call 0
        i64.mul
    end)
\end{lstlisting}

Wydajność kodu WebAssembly zbliżona jest do wykonania natywnego. Moduły operują na liniowym modelu danych, który nie jest współdzielony z~kodem języka JavaScript. Podobnie jak w~przypadku natywnych modułów występuje konieczność transformacji i~kopiowania danych do pamięci modułu, co może rodzić problemy z~wydajnością. Na listingu \ref{lst:factorial-cpp} przedstawiono funkcję liczącą silnię, która na listingu \ref{lst:factorial-wasm} została zapisana w~jej odpowiedniku w~WASM. WebAssembly przetwarzany jest w~postaci binarnej i~działa jak maszyna stosowa, a~na potrzeby analizy zapisywany jest w~formacie tekstowym w~postaci S-wyrażeń.

\subsubsection{asm.js}

Poprzednikiem WebAssembly był asm.js - podzbiór języka JavaScript w~procesie kompilacji z~języków źródłowych zoptymalizowany pod kątem wydajności wykonania i~specjalnie interpretowany przez przeglądarki wykorzystując kompilację Ahead-Of-Time. Kompilację tę wspiera do dziś jedynie przeglądarka Firefox, jednak optymalizacje silnika V8 Google Chrome 28 zapewniły dwukrotny wzrost wydajności podczas wykonania asm.js \cite{asm.js-chrome}. Nie jest on już rozwijany i~został wyparty przez WebAssembly.

\subsubsection{SIMD}

WebAssembly jest w~stanie wykorzystać architekturę SIMD (Single Instruction, Multiple Data), używając rejestrów i~instrukcji wektorowych \cite{wasm-simd}. Kompilatory takie jak LLVM potrafią, w~procesie auto-wektoryzacji wykorzystać instrukcje wektorowe, aby przyspieszyć działanie pętli oraz połączyć inne masowe operacje logiczne i~arytmetyczne. Wektoryzację taką można również przeprowadzić ręcznie wykorzystując funkcje, które operują bezpośrednio na typach wektorowych.

\subsection{Współbieżność}

W środowisku przeglądarki internetowej współbieżność osiągnięta może być tylko na poziomie wielu wątków, poprzez zastosowanie Worker'ów. Każdy Worker funkcjonuje jako osobny wątek w~ramach tego jednego procesu. Posiada on własną pętlę zdarzeń i~z głównym wątkiem komunikuje się jedynie asynchronicznymi wiadomościami. Poza obiektem \lstinline{SharedArrayBuffer}, wspieranego przez interfejs operacji atomowych \lstinline{Atomic}, aby zapobiec problemowi wyścigów, Worker'y nie współdzielą pamięci. Dane w~wiadomościach przekazywane są z~użyciem algorytmu klonowania strukturalnego, który wspiera natywne typy takie jak tablice, mapy, czy sety \cite{structured-clone}. Nie możliwe jest natomiast kopiowanie funkcji zdefiniowanych przez użytkownika oraz węzłów drzewa DOM, ponieważ tylko wątek główny może być odpowiedzialny za renderowanie widoku strony. Aby uniknąć procesu klonowania dużych zmiennych, które chcemy przenieść do Worker'a, i~które nie są potrzebne nam w~wątku głównym, możemy użyć obiektów \lstinline{Transferrable}, które jeśli wskazane, zostają przeniesione do kontekstu Worker'a, a~nie skopiowane, oszczędzając w~ten sposób pamięć i~czas procesora.

W środowiskach działających po stronie serwera współbieżne wykonanie możliwe jest przy zastosowaniu Worker'ów, ale również poprzez uruchomienie podprocesów, z~którymi można komunikować się poprzez standardowe strumienie wejścia oraz wyjścia, a~w przypadku NodeJS, również poprzez mechanizm wiadomości, który zajmuje się ich automatycznyą serializacją i~parsowaniem. 
 
\subsection{GPGPU}

GPGPU (ang. General-purpose computing on graphics processing units) zakłada użycie układów graficznych do wykonywania obliczeń ogólnego przeznaczenia, które do tej pory wykonywane były na CPU. W~środowiskach desktopowych, możemy wykorzystać takie układy używając rozwiązań powiązanych z~architekturą układu, czego przykładem jest NVIDIA CUDA. Możemy również skorzystać z~framework'ów implementujących warstwę abstrakcji będąc kompatybilnymi z~wieloma platformami i~architekturami jak na przykład OpenCL. 

Środowiska webowe zorientowane są na jak największą kompatybilność pomiędzy platformami, a~pierwotnie interakcja z~układami graficznymi możliwa była tylko w~środowisku przeglądarki internetowej poprzez wykorzystanie WebGL API do generowania grafiki w~elemencie \lstinline{<canvas/>}. Dla obliczeń ogólnego przeznaczenia stworzono standard WebCL, jednak nie zyskał on popularności i~nie był powszechnie implementowany. Sposobem, który okazał się skuteczny, aby użyć układ graficzny do innych rzeczy niż generowanie grafiki, paradoksalnie okazało się wykorzystanie procesów odpowiedzialnych za generowanie grafiki \cite{sapuan2018general}. Każdy piksel generowanego obrazu stanowić może pojedynczy wynik działania kernela czyli funkcji, której działanie jest masowo zrównoleglane. Dostarczenie danych wejściowych w~postaci tekstur oraz konstrukcja programu \texttt{Fragment Shader} wyliczającego kolor każdego wynikowego piksela pozwala wykonać obliczenia w~takiej samej abstrakcji jak dedykowane rozwiązania. 

\begin{figure}
    \centering
    \input{drawings/webglPipeline.tex}
    \caption{Potok graficzny WebGL API, który może być wykorzystany do obliczeń ogólnego przeznaczenia.}
    \label{fig:webgl-pipeline}
\end{figure}

Na rysunku \ref{fig:webgl-pipeline} przedstawiono najważniejsze elementy potoku graficznego WebGL API. Na podstawie atrybutów, które wskazują na bufory z~danymi wierzchołków, program \textit{Vertex Shader} dla każdego z~nich oblicza ich współrzędne. Następnie po procesie transformacji wierzchołków na prymitywy (najczęściej trójkąty) i~ich rasteryzacji, program \textit{Fragment Shader} zajmuje się obliczeniem koloru każdego piksela wynikowego obrazu na podstawie interpolowanych wartości dostarczanych w~postaci \textit{Varyings}. Omijając etap związany z~pozycją wierzchołków i~wymuszając tylko kolorowanie właściwej liczby pikseli, możemy przenieść obliczenia do programu \textit{Fragment Shader}, gdzie dane wejściowe dostarczane są w~postaci tekstur za pomocą \textit{Uniforms}, czyli stałych dla całego potoku.

Podejście to, z~racji na specyficzność tego potoku, ma swoje ograniczenia. W~przeciwieństwie do pozostałych rozwiązań GPGPU jedynym wynikiem działania kernela jest wartość piksela. Niemożliwe zatem jest zapis do pamięci współdzielonej w~trakcie wykonywania algorytmu. Wąskie gardło wydajności stanowi odczyt wyników. Proces wysłania bufora ramki i~wyświetlenia go na elemencie \lstinline{<canvas/>} jest zoptymalizowany, jednak pobranie go z~GPU do postaci typowanej tablicy w~języku JavaScript jest już kosztowne czasowo.

W środowisku przeglądarki internetowej dostępny jest WebGL, a~co za tym idzie, istnieje możliwość wykorzystanie tej metody akceleracji obliczeń. Środowiska NodeJS oraz Deno, jako rozwiązania serwerowe, nie skupiły się na mechanizmach generowania grafiki. W~środowisku NodeJS istnieją jednak biblioteki implementujące kontekst WebGL, na przykład \textit{headless-gl} \cite{headless-gl}. Środowisko Deno, z~racji na swój młody wiek, na chwilę obecną nie posiada implementacji natywnej, jak i~w postaci bibliotek. 

\subsubsection{WebGPU}

Popularyzacja i~potrzeba tworzenia coraz bardziej wydajnych aplikacji webowych, sprowokowała powstanie specyfikacji WebGPU API, która stanowi uogólnienie przetwarzania masowo równoległego dostarczając bezpośrednio abstrakcję GPU \cite{webgpu_2022}. WebGPU może być wykorzystane do obliczeń ogólnego przeznaczenia, ale również do generowania grafiki. Obecnie jest jednak wciąż dostępne jako funkcjonalność eksperymentalna i~do działania w~środowisku przeglądarki internetowej oraz Deno potrzebuje specjalnej flagi. Środowisko NodeJS nie implementuje \mbox{WebGPU}.
