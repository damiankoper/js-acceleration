\chapter{Język JavaScript}

JavaScript od momentu swojego powstania w~1995 roku stanowił jeden z~filarów rozwoju technologii webowych, zaczynając od dodania prostych mechanizmów interaktywności do statycznych stron internetowym, a~kończąc na byciu nieraz jedynymi samodzielnym budulcem pełnowymiarowych aplikacji działających po stronie klienta i~serwera, aplikacji działających w~środowisku przeglądarki internetowej, ale też w~środowiskach natywnych, desktopowych i~mobilnych. Dlatego, aby zrozumieć w~pełni specyfikę problemu, który stanowi przystosowanie języka do wykonywania obliczeń numerycznych, w~tym rozdziale przybliżone zostały zagadnienia związane z~modelem wykonania, środowiskami oraz sposobami na podział kodu na moduły oraz późniejsze ich wykorzystanie. Na końcu opisane zostały metody akceleracji, dla których przeprowadzono badania.



\section{Model wykonania}

Model wykonania języka JavaScript skoncentrowany jest w~głównej mierze na obsłudze zdarzeń. W~przeglądarce internetowej zdarzeniami takimi mogą być interakcje z~użytkownikiem, na przykład kiedy naciśnięty zostanie przycisk, albo interakcje z~siecią, kiedy otrzymamy odpowiedź na zapytanie z~wykorzystaniem obiektu \lstinline{XMLHttpRequest} lub skorzystamy z~Fetch API. Po stronie serwera zdarzeniami takimi mogą być odebranie zapytania, które serwer musi obsłużyć, obsługa strumieni, ale także wszelkie odpowiedzi na interakcje z~systemem operacyjnym. Podstawowymi interakcjami może być obsługa sygnałów, dostęp do plików, czy też obsługa sieci, która umożliwia połączenie na przykład z~bazą danych.

Zdarzenia te obsługuje pętla zdarzeń (ang. event loop). Na rysunku \ref{fig:event-loop} pokazano jej uproszczony model. Wyróżnia ona zadania, zwane także makro zadaniami, oraz mikro zadania. Dla każdego typu zadań utworzona zostaje osobna kolejka. Jeśli aktualnie wykonywane przetwarzanie sekwencyjne, którego ramki wywołań śledzone są na stosie, zakończy się, wtedy z~pętli zdarzeń pobierane i~wykonywane jest makro lub mikro zadanie. W~pierwszej kolejności wykonywane są wszystkie mikro zadania, a~gdy ich kolejka jest pusta, wykonywane jest kolejne makro zadanie.

Makro zadania dodawane są do kolejki, aby obsłużyć wspomniane już zdarzenia związane z~działaniami użytkownika lub inne zewnętrzne zdarzenia. Są one również dodawane do kolejki, kiedy mija czas zadany podczas wywołań funkcji \lstinline{setTimeout()} oraz \lstinline{setInterval()}. Warto zaznaczyć, że wywołania tych funkcji nie gwarantują wykonania dokładnie po zadanym czasie, ale traktują go jako próg czasowy, po jakim zadana funkcja zostanie dodana do kolejki makro zadań \cite{setTimeout}. Makro zadania dodane podczas jednej iteracji pętli nigdy nie zostaną wykonane w~tej samej iteracji.

Mikro zadania pochodzą tylko i~wyłącznie z~kodu użytkownika, bądź bibliotek i~wykorzystywane są do obsługi asynchronicznych zadań, zarządzania ich kolejnością i~obsługą błędów\cite{runtime}. Do ich tworzenia wykorzystuje się głównie obiekt \lstinline{Promise}}, który reprezentuje zadanie, które w~przyszłości zakończy się pomyślnie lub błędem. Dla takiego obiektu zdefiniować możemy funkcje, które wykonają się podczas scenariusza pomyślnego (\lstinline{then}), błędnego (\lstinline{catch}) oraz zawsze (\lstinline{finally}) \cite{promise}. Mikro zadania pochodzić mogą również od obserwatorów na przykład \lstinline{MutationObserver}, czy \lstinline{ResizeObserver}.

Zrozumienie sposobu wykonywania kodu w~asynchronicznym modelu języka JavaScript jest kluczowe do efektywnego wykorzystania możliwości, jakie idą za metodami akceleracji, których użycie możliwe jest tylko i~wyłącznie poprzez asynchroniczne wywołania. Opisane w~sekcji \ref{sec:acc-methods} metody bazujące na Worker'ach oraz WebGL wymagają interakcji poprzez wywołania asynchroniczne. Na listingu \ref{lst:async} pokazano przykład kodu asynchronicznego. Wywołania \lstinline{console.log} wykonają się, zawsze drukując liczby w~kolejności od 1 do 6.

\lstinputlisting[language=JavaScript, caption=Przykład kodu demonstrujący mechanizmy asynchroniczności w~języku JavaScript., label=lst:async] {./code/async.js}

Linijki 1 oraz 6 zostają wykonene synchronicznie. \lstinline{Promise} w~linijce 5 zostaje wykonany jako następny, ponieważ jako mikro zadanie, wykona się zaraz po operacjach synchronicznych. Następnie funkcje \lstinline{setTimeout} wykonają się w~kolejności ich wywołania, gdzie w~linijkach 2-4 na ich kolejność wpływ maja mechanizm \lstinline{Promise}. Timeout z~linijki 3, a~potem 4 zostają wywołane jaki pierwsze. Jako ostatni wykonuje się timeout z~linijki 2, ponieważ jego wywołanie, w~postaci mikro taska, przeniesione zostało na koniec wykonania synchronicznego.

\begin{figure}
    \centering
    \input{drawings/eventLoop}
    \caption{Uproszczony model pętli zdarzeń środowisk języka JavaScript w~wariancie z~wyróżnieniem API przeglądarek internetowych.}
    \label{fig:event-loop}
\end{figure}

\section{Środowiska JavaScript}
\label{sec:env-modules}

Rosnąca popularność języka JavaScript i~idących za jego stosowaniem możliwości przyspieszyła rozwój środowisk, w~którym kod języka mógł być wykonywany. Pierwszym z~nich była przeglądarka internetowa. 

\subsection{Przeglądarka internetowa}

Głównym zadaniem przeglądarki internetowej jest pobieranie z~sieci i~wyświetlanie zawartości użytkownikowi oraz obsługa jego interakcji. Najważniejszym komponentem przeglądarki jest silnik renderujący, który zawiera silniki odpowiedzialne za parsowanie i~renderowanie struktury modelu DOM, adaptery służące do wywołań dostępnych bibliotek graficznych (OpenGL, Vulcan, DirectX) oraz silnik JavaScript. Z~perspektywy tej pracy to właśnie silnik JavaScript jest najważniejszym komponentem silnika renderującego. Silnik języka zajmuje się parsowaniem, kompilacją do bytecode'u, interpretowaniem oraz późniejszą optymalizacją kodu. Posiada wiele możliwości optymalizacji spekulatywnej z~racji na specyfikę języka, który jest dynamicznie typowany \cite{meurer_2017}.

Popularnymi silnikami renderującymi są Blink z~silnikiem JavaScript V8 \cite{V8} oraz Gecko z~silnikiem JavaScript SpiderMonkey \cite{spidermonkey}. Silniki JavaScript skupione są na szybkim i~efektywnym wykonywaniu kodu i~nie zajmują się asynchronicznością i~pętlą zdarzeń. Odpowiedzialne za to są równolegle biblioteki. W~przeglądarce Google Chrome pętlę zdarzeń implementuje biblioteka LibEvent \cite{libevent}.

\subsection{NodeJS}

NodeJS jest powstałym w~2009 roku środowiskiem, które było odpowiedzią na architekturę pozostałych rozwiązań serwerowych, które angażują wiele procesów i~wątków do obsługi wielu zapytań w~tym samym czasie. Rodzi to problemy związane z~koniecznością przełączania kontekstu pomiędzy procesami oraz większe zapotrzebowanie na pamięć. Również każda operacja wejścia-wyjścia musi być synchroniczna, co prowadzi do zablokowania całego procesu w~oczekiwaniu na odpowiedź \cite{nodejs}.

Problemy te rozwiązało środowisko NodeJS, napisane w~C++ i~oparte na silniku V8. Razem biblioteką LibUv \cite{libuv} implementującą pętlę zdarzeń w~ramach jednego procesu wykonującego kod JavaScript użytkownika oraz wielu wątków, które realizują oczekiwanie na operacje asynchroniczne, pozwoliło rozwiązać problem operacji wejścia-wyjścia pozwalając w~ramach tych samych zasobów sprzętowych osiągnąć lepsza wydajność niż popularny serwer Apache \cite{node-apache}. Na rysunku \ref{fig:nodejs} pokazano architekturę środowiska NodeJS, która stoi pomiędzy aplikacją, a~systemem operacyjnym.

\begin{figure}
    \centering
    \input{drawings/node} 
    \caption{Model architektury środowiska NodeJS.}
    \label{fig:nodejs}
\end{figure}

\subsection{Deno}

Deno powstał w~2018 roku, a~jego wersja 1.0.0 wydana została w~2020 roku. Jest to środowisko aspirujące do bycia następcą NodeJS rozwiązując jego problemy związane z~bezpieczeństwem, systemem budowania zależności bibliotek, czy importowania zależności \cite{deno}. Podobnie jak NodeJS do wykonywania kody JavaScript wykorzystuje silnik V8, ale napisany jest w~języku Rust. Do obsługi asynchroniczności i~pętli zdarzeń wykorzystuje bibliotekę Tokio \cite{tokio}. W~przeciwieństwie do NodeJS i~przeglądarek internetowych obsługuje natywnie TypeScript - nadzbiór języka JavaScript umożliwiający wykorzystanie statycznego typowania oraz wszystkie zalety za tym idące.

\section{Modularność i~kompatybilność kodu}

Kolejnym ważnym aspektem rozważań jest modularność i~kompatybilność kodu pomiędzy środowiskami. Rozwój bibliotek języków jest naturalnym krokiem ewolucji ekosystemu i~aby taki ekosystem był ogólnodostępny, biblioteki dostępne są dla wszystkich w~postaci scentralizowanego rejestru paczek. 

\subsection{Modularność}

Dla środowiska NodeJS najpopularniejszym rejestrem jest \textit{npm registry} (npm - node package manager). Za pomocą narzędzia o~tej samej nazwie można instalować i~zatrzaskiwać wersję paczek, które trafiają do folderu \lstinline{node_modules}, w~którym środowisko NodeJS domyślnie poszukuje kodu podczas importu paczek. Zainstalowane paczki są opisane wraz z~ich wersją w~pliku \lstinline{package.json} i~\lstinline{package-lock.json}, gdzie pierwszy z~nich zawiera wymaganą wersję zapisaną w~konwencji Semver \cite{semver}, a~drugi zatrzaśnięte zainstalowane wersje, co pozwala odtworzyć dokładną strukturę zależności.

Przeglądarki internetowe z~kolei pobierają dodatkowe biblioteki poprzez umieszczenie tagów \lstinline{<script/>} w~dowolnym miejscu na stronie, często z~użyciem sieci CDN (ang. content delivery network). \textit{npm} jest również popularnym rozwiązaniem służącym do dostarczania modułów niezbędnych do funkcjonowania stronom internetowym, jednak odbywa się to pośrednio. Za pomocą narzędzi zwanych bundler'ami, ze wszystkich niezbędnych zależności - właściwego kodu strony oraz zewnętrznych bibliotek instalowanych przy pomocy narzędzia \textit{npm}, budowany jest pojedynczy plik, który następnie jest ładowany przez przeglądarkę. Pomaga to zaoszczędzić liczbę połączeń przeglądarki do serwerów, a~co za tym idzie zaoszczędzić czas spędzony na inicjowaniu połączenia i~pobieraniu danych w~szczególności, że liczba możliwych otwartych połączeń przez przeglądarkę internetową jest limitowana (10 w~Google Chrome). Często obecnie budowane są dwa lub więcej plików - jeden z~bibliotekami zewnętrznymi oraz jeden lub więcej z~właściwym kodem strony w~celu wykorzystania mechanizmów pamięci podręcznej przeglądarki oraz dynamicznego i~opóźnionego ładowania niezbędnego kodu, co przyspiesza ładowanie strony. Popularnymi bundler'ami są Webpack, Snowpack, Parcel, Rollup oraz Vite.

Deno próbuje rozwiązać problem importowania modułów w~NodeJS, który wynika z~scentralizowanego rejestru i~paczek oraz z~faktu istnienia plików \lstinline{package*.json} i~konieczności wykonania procesu instalacji. Pobiera on zależności bezpośrednio z~internetu i~wkłada do pamięci podręcznej. Link do zależności jest jej jednoznacznym identyfikatorem, a~to znaczy, że powinien zawierać wersję paczki i~nigdy nie zmienić swojej zawartości. Pobranie i~kompilacja zależności w~czasie wykonania programu likwiduje potrzebę przechowywania listy zależności i~ich wersji oraz niweluje potrzebę ich instalacji. Deno wykorzystuje opisany w~dalszej części rozdziału format modułów ESM.

Niezależnie od tego gdzie przetrzymywane są moduły oraz w~jaki sposób są zarządzane przez środowisko, muszą one być finalnie przez nie skonsumowane. Na przykład mogą być one użyte bezpośrednio, ale też przetransformowane w~procesie budowania biblioteki, która będzie potem dalej konsumowana, czy paczki dla przeglądarki internetowej. W~procesie ewolucji ekosystemu języka JavaScript wykształciło się wiele formatów modułów. Niektóre z~nich są kompatybilne tylko z~przeglądarką internetową, niektóre tylko ze środowiskiem NodeJS bądź Deno.  

\subsubsection{AMD}

AMD (Asynchronous Module Definition) jest sposobem ładowania zależności w~przeglądarkach internetowych. Rozwija wzorzec modułów JavaScript \cite{jsmodulepattern} poprzez dodanie asynchronicznego pobierania i~ładowania zależności. Moduł jest funkcją, dzięki czemu zadeklarowane zmienne nie wyciekają poza jej zakres, a~jej wartość zwracana stanowi wartość, którą taki moduł eksportuje. Zadeklarowanie modułu i~jego zależności w~formacie AMD umożliwia funkcja \lstinline{define}.

\subsubsection{CommonJS}

Format CommonJS utworzony został na potrzeby środowiska NodeJS i~jest tam do dzisiaj wykorzystywany. Używa on globalnie dostępnej funkcji \lstinline{require}, która jako argument przyjmuje nazwę modułu lub relatywną ścieżkę do pliku \lstinline{*.js}, jednak z~pominięciem jego rozszerzenia, co stanowi problem podczas wyszukiwania modułów przez środowisko. Moduł może eksportować funkcje i~wartości poprzez dodanie ich do obiektu \lstinline{module.exports}. Pliki z~modułami w~tym formacie, aby lepiej je identyfikować, mogą mieć rozszerzenie \lstinline{*.cjs}.

\subsubsection{UMD}

UMD (Universal Module Definition) nie stanowi samodzielnego formatu, ale integruje formaty AMD, CommonJS oraz użycie zmiennych globalnych do definicji modułu i~jego zależności. Wyewoluował on z~potrzeby tworzenia bibliotek kompatybilnych z~wieloma środowiskami, dla których nie trzeba budować wielu wersji w~różnych formatach.

\subsubsection{Moduły ECMAScript}

Brak kompatybilności i~wiele formatów modułów, gdzie każde środowisko zaproponowało swój własny spowodowało ich standaryzację. ECMAScript, którego implementacją jest JavaScript, w~wersji 2015 (zwanej również ES6) wprowadza definicję modułów zwanych ESModules, ESM \cite{ESModules}. Obecnie wspierane są one przez wszystkie analizowane tutaj środowiska i~są zalecaną metodą importowania zależności. Używają one słów kluczowych \lstinline{import} oraz \lstinline{export} tak, jak zostało to pokazane na listingu \ref{lst:esm}. Od wersji ES11 specyfikacji możliwe stało się dynamiczne importowanie modułów podczas wykonania, gdzie jako rezultat otrzymujemy obiekt \mbox{\lstinline{Promise}}. Pliki z~modułami w~tym formacie, aby lepiej je identyfikować, mogą mieć rozszerzenie \mbox{\lstinline{*.mjs}}. Wszystkie biblioteki wykorzystujące metody akceleracji badane w~tej pracy budowane są z~wykorzystaniem ESM.

\begin{lstlisting}[language=JavaScript, caption=Przykład wykorzystania ECMAScript Modules, label=lst:esm]
// main.mjs
import { add } from "./module"
console.log(add(2+2));

// module.mjs
export function add(foo, bar) { return foo + bar; }
\end{lstlisting}

\subsection{Kompatybilność}

Szerokie starania w~standaryzacji modułów umożliwiają tworzenie kodu kompatybilnego z~wieloma środowiskami. Jeśli jednak kod ten korzysta z~funkcjonalności samego środowiska, która istnieje w~pozostałych środowiskach, ale ich API nie są ze sobą zgodne, problem kompatybilności między środowiskami wciąż występuje. Wprowadza to niechciane mechanizmy do kodu wykrywające środowisko i~wymusza wykorzystanie wzorców projektowych takich jak \textit{adapter}, w~celu obsługi wszystkich wariantów API.

Przykładem takiego rozwiązania jest biblioteka \textit{axios}, która służy do wykonywania zapytań HTTP. W~środowisku przeglądarki internetowej do wykonywania zapytań wykorzystuje obiekt \lstinline{XMLHttpRequest}, a~w środowisku NodeJS wbudowany moduł \textit{http}. Rozwiązaniem problemu w~tym przypadku może być użycie Fetch API, które jako pierwsze zadebiutowało w~przeglądarkach internetowych oraz zaadaptowane zostało przez NodeJS, a~w Deno jest ono domyślnie przewidzianą formą wykonywania zapytań HTTP.

Innym przykładem braku kompatybilności pomiędzy podobnymi funkcjonalnościami jest wielowątkowość, która istnieje pod abstrakcją Worker'ów i~dokładnie zostanie omówiona w~rozdziale \ref{sec:acc-methods}. Przeglądarki internetowe oraz Deno, który ma na celu możliwie zbliżyć się do nich ze swoim API, implementują Web Worker API. NodeJS z~kolei do obsługi Worker'ów wykorzystuje wbudowany moduł \textit{worker\_threads}, który różni się od jego odpowiedników.    

\section{Metody akceleracji}
\label{sec:acc-methods}

Akceleracja obliczeń jest niekończącą się pogonią za nieskończenie krótkim czasem wykonania algorytmów. Zdaniem autora powinna być ona brana pod uwagę na każdym etapie ich rozwoju - od etapu prototypowania, do wdrożeń produkcyjnych, ponieważ na każdym z~nich może przynieść wymierne korzyści. Wspomnianą w~poprzednim rozdziale akcelerację praca traktuje jako wszelkie metody przyspieszające wykonywanie algorytmu.

\subsection{Optymalizacja wykonania sekwencyjnego}

Pierwszym aspektem, na który trzeba zwrócić uwagę jest sama interakcja z~silnikiem języka i~wykorzystanie jego możliwości oraz tego w~jaki sposób potrafi on optymalizować wykonywany kod. Poprzez kompilację kodu Just-In-Time (JIT), czyli bezpośrednio przed jego wykonaniem oraz możliwość powtarzania tego procesu wykorzystując heurystyki dla zebranych danych, możliwe jest przyspieszenie wykonania kodu \cite{meurer_2017}. W~przypadku silnika V8 kod najpierw trafia do interpretera o~nazwie Ignition, gdzie kompilowany jest do bytecode'u, który zamieniany jest na instrukcje zgodne z~architektura procesora. Równolegle bytecode wysyłany jest do kompilatora TurboFan, gdzie przechodzi optymalizację na poziomie funkcji, w~przeciwieństwie do innych rozwiązań JIT, które identyfikują wielokrotnie wykonywaną część bytecode'u \cite{meurer_2019}. Optymalizacja ta jest ograniczona do funkcji o~maksymalnym rozmiarze bytecode'u równym 60KB, więc ważne jest, aby umiejętnie rozbijać kod algorytmu na funkcje i~moduły.

Osoba projektująca dany algorytm może celowo unikać konstrukcji języka oraz niektórych wzorców, aby wspomóc mechanizmy optymalizacji i~zwiększyć wydajność w~skrajnych przypadkach nawet o~25\% (\cite{gong2015jitprof}, \cite{selakovic2016performance}). Dobrą praktyką jest stosowanie typowanych tablic (Typed Array) do przechowywania danych binarnych oraz danych o~znanym typie. Innym sposobem poprawny wydajności jest modyfikacja algorytmu tak, aby zredukować obciążenie związane z~obliczeniami zmiennoprzecinkowymi, na przykład poprzez stosowanie stablicowanych wartości funkcji trygonometrycznych (LUT).

\subsection{Natywne moduły}

Środowiska NodeJS i~Deno działające po stronie serwera pozwalają na uruchomienie z~ich poziomu bibliotek skompilowanych do kodu maszynowego konkretnej architektury. Deno pozwala uruchomić funkcję ze skompilowanego kodu języka Rust do postaci biblioteki na różnych platformach (\lstinline{*.so}, \lstinline{*.dll}, \lstinline{*.dylib}). NodeJS natomiast posiada własny system budowania natywnych modułów z~kodu C++ o~nazwie \textit{node-gyp}, którego zależnością jest język Python.

Zaletą korzystania z~natywnych modułów jest możliwość wykorzystania metod optymalizacji specyficznych dla platformy sprzętowej, jaki oferują języki niskiego poziomu kompilowane do kodu maszynowego. Metodę tę można rozwinąć o~metody akceleracji dostępne w~językach źródłowych, których przykładem może być wielowątkowość z~wykorzystaniem biblioteki \lstinline{pthreads}. Do wad takiego rozwiązania zaliczyć można konieczność pobierania lub budowania natywnych zależności w~momencie instalacji biblioteki oraz ogólną kompatybilność, która wykracza poza środowisko języka JavaScript. Wadą, która wpływa w~znaczącym stopniu na wydajność w~specyficznych przypadkach jest brak bezpośredniego dostępu do pamięci silnika JavaScript, co skutkuje koniecznością kopiowania danych w~warstwie powiązania natywnego modułu z~kodem języka JavaScript. Dla dużych danych proces ten okazać się może wąskim gardłem algorytmu.

\subsection{WebAssembly}

Kolejną metodą akceleracji wykonania sekwencyjnego jest WebAssembly (WASM), który jest językiem niskiego poziomu. Stanowi on cel kompilacji języków takich jak C++, czy Rust i~pozwala uruchamiać w~środowisku webowym złożonych aplikacji, których wcześniejsze uruchomienie nie było możliwe ze względu na konieczność parsowania i~kompilacji dużej ilości kodu. Umożliwiło to na przykład łatwe przeniesienie aplikacji napisanych w~języku C++ z~wykorzystaniem biblioteki Qt i~uruchomienie ich w~przeglądarce internetowej \cite{qt-wasm}. Inny przykładem jest jeden z~backend'ów biblioteki Tensorflow.js \cite{tensorflowjs}, która umożliwia trenowanie i~wdrażanie modeli uczenia maszynowego.

\begin{lstlisting}[language=C++, caption=Funkcja licząca silnię w~języku C/C++, label=lst:factorial-cpp]
int factorial(int n) {
    if (n == 0)
        return 1;
    else
        return n * factorial(n-1);
}
\end{lstlisting}
    
\begin{lstlisting}[language=WASM, caption=Funkcja licząca silnię w~języku WASM, label=lst:factorial-wasm]
(func (param i64) (result i64)
    local.get 0
    i64.eqz
    if (result i64)
        i64.const 1
    else
        local.get 0
        local.get 0
        i64.const 1
        i64.sub
        call 0
        i64.mul
    end)
\end{lstlisting}

Wydajność kodu WebAssembly zbliżona jest do wykonania natywnego. Moduły operują na liniowym modelu danych, który nie jest współdzielony z~kodem języka JavaScript. Podobnie jak w~przypadku natywnych modułów występuje konieczność transformacji i~kopiowania danych do pamięci modułu, co może rodzić problemy z~wydajnością. Na listingu \ref{lst:factorial-cpp} przedstawiono funkcję liczącą silnię, która na listingu \ref{lst:factorial-wasm} została zapisana w~jej odpowiedniku w~WASM. WebAssembly przetwarzany jest w~postaci binarnej i~działa jak maszyna stosowa, a~na potrzeby analizy zapisywany jest w~formacie tekstowym w~postaci S-wyrażeń.

\subsubsection{asm.js}

Poprzednikiem WebAssembly był asm.js - podzbiór języka JavaScript w~procesie kompilacji z~języków źródłowych zoptymalizowany pod kątem wydajności wykonania i~specjalnie interpretowany przez przeglądarki wykorzystując kompilację Ahead-Of-Time. Kompilację tę wspiera do dziś jedynie przeglądarka Firefox, jednak optymalizacje silnika V8 Google Chrome 28 zapewniły dwukrotny wzrost wydajności podczas wykonania asm.js \cite{asm.js-chrome}. Nie jest on już rozwijany i~został wyparty przez WebAssembly.

\subsubsection{SIMD}

WebAssembly jest w~stanie wykorzystać architekturę SIMD (Single Instruction, Multiple Data), używając rejestrów i~instrukcji wektorowych \cite{wasm-simd}. Kompilatory takie jak LLVM potrafią, w procesie auto-wektoryzacji wykorzystać instrukcje wektorowe, aby przyspieszyć działanie pętli oraz połączyć inne masowe operacje logiczne i arytmetyczne. Wektoryzację taką można również przeprowadzić ręcznie wykorzystując funkcje, które operują bezpośrednio na typach wektorowych.

\subsection{Współbieżność}

W środowisku przeglądarki internetowej współbieżność osiągnięta może być tylko na poziomie wielu wątków. Wielowątkowość może zostać osiągnięta poprzez zastosowanie Worker'ów. Każdy Worker funkcjonuje jako osobny wątek w ramach tego jednego procesu. Posiada on własną pętlę zdarzeń i z głównym wątkiem komunikuje się jedynie asynchronicznymi wiadomościami. Poza obiektem \lstinline{SharedArrayBuffer}, wspieranego przez interfejs operacji atomowych \lstinline{Atomic}, aby zapobiec problemowi wyścigów, worker'y nie współdzielą pamięci. Dane w wiadomościach przekazywane są z użyciem algorytmu klonowania strukturalnego, który wspiera natywne typy takie jak tablice, mapy, czy sety \cite{structured-clone}. Nie możliwe jest natomiast kopiowanie funkcji zdefiniowanych przez użytkownika oraz węzłów drzewa DOM, ponieważ tylko wątek główny może być odpowiedzialny za renderowanie widoku strony. Aby uniknąć procesu klonowania dużych zmiennych, które chcemy przenieść do Worker'a, i które nie są potrzebne nam w wątku głównym, możemy użyć obiektów \lstinline{Transferrable}, które jeśli wskazane, zostają przeniesione do kontekstu Worker'a, a nie skopiowane, oszczędzając w ten sposób pamięć i czas procesora.

W środowiskach działających po stronie serwera współbieżne wykonanie możliwe jest przy zastosowaniu Worker'ów, ale również poprzez uruchomienie podprocesów, z którymi można komunikować się poprzez standardowe strumienie wejścia oraz wyjścia, a w przypadku NodeJS, poprzez mechanizm wiadomości, który zajmuje się ich serializacją i parsowaniem. 
 
\subsection{GPGPU}

GPGPU (ang. General-purpose computing on graphics processing units) zakłada użycie układów graficznych do wykonywania obliczeń ogólnego przeznaczenia, które do tej pory wykonywane były na CPU. Środowiska, w zależności od dostępności układów graficznych, w środowiskach desktopowych, możemy wykorzystać takie układy używając rozwiązań powiązanych z architekturą układu, czego przykładem jest NVIDIA CUDA. Możemy również skorzystać z framework'ów współpracującymi z wieloma platformami i architekturami jak na przykład OpenCL. 

Środowiska webowe zorientowane są na jak największą kompatybilność pomiędzy platformami, a pierwotnie interakcja z układami graficznymi możliwa była tylko w środowisku przeglądarki internetowej poprzez wykorzystanie WebGL API do generowania grafiki w elemencie \lstinline{<canvas/>}. Dla obliczeń ogólnego przeznaczenia stworzono standard WebCL, jednak nie zyskał popularności i nie był powszechnie implementowany. Sposobem, który okazał się skuteczny, aby użyć układ graficzny do innych rzeczy niż generowanie grafiki, paradoksalnie okazało się wykorzystanie procesów odpowiedzialnych za generowanie grafiki \cite{sapuan2018general}. Każdy piksel generowanego obrazu stanowić może pojedynczy wynik działania kernela. Dostarczenie danych wejściowych w postaci tekstur oraz konstrukcja programu \texttt{Fragment Shader} wyliczającego kolor każdego wynikowego piksela pozwala wykonać obliczenia w takiej samej abstrakcji jak dedykowane rozwiązania.

% TODO własna wersja pipeline https://www.wisdomjobs.com/userfiles/gp1.png

\begin{figure}
    \centering
    
    \caption{Pipeline graficzny WebGL API, który może byż wykorzystany do obliczeń ogólnego przeznaczenia.}
    \label{fig:nodejs}
\end{figure}


% TODO wady, random writes niemożliwe, readpixels
% TODO kompatybilność node (headless), deno (brak)
